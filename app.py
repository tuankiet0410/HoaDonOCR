import streamlit as st
import google.generativeai as genai
from PIL import Image
import json
import pandas as pd
import base64
import requests
import numpy as np
from io import BytesIO
import re
import gc
import cv2 

# ================= Optional OCR Backends =================
try:
    from paddleocr import PaddleOCR
    if 'paddle_ocr' not in st.session_state:
        # Kh·ªüi t·∫°o PaddleOCR (ch·ªâ ch·∫°y 1 l·∫ßn)
        st.session_state.paddle_ocr = PaddleOCR(use_textline_orientation=True, lang="vi")
        print("[INFO] PaddleOCR initialized successfully.")
    paddle_ocr = st.session_state.paddle_ocr
except Exception as e:
    paddle_ocr = None
    st.warning(f"PaddleOCR init error: {e}\nN·∫øu ch∆∞a c√†i: pip install paddleocr paddlepaddle")
    print("[ERROR] PaddleOCR init failed:", e)

# ================= API Keys (S·ª≠ d·ª•ng Streamlit Secrets) =================
try:
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    GOOGLE_API_KEY = st.secrets.get("GOOGLE_API_KEY")

except KeyError as e:
    missing_key = e.args[0]
    st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y secret '{missing_key}'.")
    st.info(f"Vui l√≤ng v√†o 'Manage app' -> 'Settings' -> 'Secrets' v√† th√™m '{missing_key}' v√†o.")
    st.stop()
except FileNotFoundError: # L·ªói n√†y th∆∞·ªùng kh√¥ng x·∫£y ra tr√™n Cloud
    st.error("L·ªói: Kh√¥ng t√¨m th·∫•y file .streamlit/secrets.toml.")
    st.info("Vui l√≤ng t·∫°o file .streamlit/secrets.toml v√† th√™m API keys v√†o ƒë√≥.")
    st.stop()


# ================= Configure Gemini =================
if not GEMINI_API_KEY:
    st.error("L·ªói: B·∫°n ch∆∞a cung c·∫•p Gemini API Key trong file secrets.")
    st.stop()

try:
    genai.configure(api_key=GEMINI_API_KEY)
    print("[INFO] Gemini API configured.")
except Exception as e:
    st.error(f"L·ªói khi c·∫•u h√¨nh Gemini API: {e}")
    st.stop()

# ================= Gemini Prompt =================
def get_gemini_prompt():
    """Tr·∫£ v·ªÅ prompt chu·∫©n cho Gemini."""
    return """
B·∫°n l√† m·ªôt chuy√™n gia x·ª≠ l√Ω h√≥a ƒë∆°n.
Nhi·ªám v·ª• c·ªßa b·∫°n l√† tr√≠ch xu·∫•t th√¥ng tin chi ti·∫øt t·ª´ h√¨nh ·∫£nh h√≥a ƒë∆°n ƒë∆∞·ª£c cung c·∫•p.

N·∫øu b·∫°n ch·ªâ ƒë∆∞·ª£c ƒë∆∞a TEXT, h√£y ph√¢n t√≠ch TEXT ƒë√≥.

H√£y tr·∫£ v·ªÅ m·ªôt ƒë·ªëi t∆∞·ª£ng JSON:
{
  "items": [
    {
      "ten_hang": "...",
      "don_vi_tinh": "...",
      "so_luong": number/null,
      "don_gia": number/null,
      "thanh_tien": number/null
    }
  ],
  "tong_tien": number/null
}

QUAN TR·ªåNG:
- Ch·ªâ tr·∫£ l·ªùi JSON.
- Kh√¥ng th√™m m√¥ t·∫£.
- N·∫øu kh√¥ng th·∫•y tr∆∞·ªùng n√†o -> tr·∫£ null.
"""

# ================= OCR Backends =================
@st.cache_data(show_spinner=False)
def ocr_google_vision_api_key(image_bytes):
    """S·ª≠ d·ª•ng Google Vision API ƒë·ªÉ OCR ·∫£nh (ƒë√£ ƒë∆∞·ª£c cache)."""
    # S·ª≠ d·ª•ng GOOGLE_API_KEY ƒë√£ load t·ª´ secrets
    if not GOOGLE_API_KEY:
        st.error("B·∫°n ch∆∞a cung c·∫•p Google Vision API Key trong file secrets.")
        return ""
        
    img_base64 = base64.b64encode(image_bytes).decode()
    url = f"https://vision.googleapis.com/v1/images:annotate?key={GOOGLE_API_KEY}"
    payload = {
        "requests": [
            {
                "image": {"content": img_base64},
                "features": [{"type": "TEXT_DETECTION"}]
            }
        ]
    }
    response = requests.post(url, json=payload)
    res_json = response.json()
    text = ""
    try:
        resp0 = res_json.get("responses", [{}])[0]
        if "error" in resp0:
            print("Google Vision API Error:", resp0["error"])
            st.error(f"Google Vision API Error: {resp0['error'].get('message', 'Unknown error')}")
        elif "fullTextAnnotation" in resp0:
            text = resp0["fullTextAnnotation"]["text"]
    except Exception as e:
        print("L·ªói parse Google Vision response:", e)
    print(f"[OCR Google Vision] K·∫øt qu·∫£ OCR:\n{text}\n{'-'*40}")
    return text

@st.cache_data(show_spinner=False)
def ocr_paddle(image_array_bgr):
    """S·ª≠ d·ª•ng PaddleOCR ƒë·ªÉ OCR ·∫£nh (ƒë√£ ƒë∆∞·ª£c cache).
    L∆∞u √Ω: PaddleOCR y√™u c·∫ßu ·∫£nh ·ªü ƒë·ªãnh d·∫°ng BGR (np.array).
    """
    if paddle_ocr is None:
        raise RuntimeError("PaddleOCR ch∆∞a ƒë∆∞·ª£c c√†i ho·∫∑c kh·ªüi t·∫°o th·∫•t b·∫°i.")
    try:
        # PaddleOCR x·ª≠ l√Ω ·∫£nh BGR
        result = paddle_ocr.predict(image_array_bgr, use_textline_orientation=True)
    except Exception as e:
        raise RuntimeError(f"PaddleOCR predict l·ªói: {e}")
    all_text = []
    if not result or result == [None]:
        print("[WARN] PaddleOCR returned no results.")
        return ""
    for page_result in result:
        # Ki·ªÉm tra ƒë·ªãnh d·∫°ng tr·∫£ v·ªÅ c·ªßa PaddleOCR (c√≥ th·ªÉ l√† list ho·∫∑c dict)
        current_texts = []
        if isinstance(page_result, dict):
            # ƒê·ªãnh d·∫°ng m·ªõi (dictionary)
            current_texts = page_result.get('rec_texts', [])
        elif isinstance(page_result, list):
             # ƒê·ªãnh d·∫°ng c≈© (list of tuples)
            current_texts = [line[0] for line in page_result if isinstance(line, (list, tuple)) and len(line) > 0]

        all_text.extend(current_texts)

    text = "\n".join(all_text)
    print(f"[OCR PaddleOCR] K·∫øt qu·∫£ OCR:\n{text}\n{'-'*40}")
    return text

# ================= Gemini JSON extractor =================
@st.cache_data(show_spinner=False)
def extract_invoice_json(text_or_image_data):
    """G·ª≠i text (str) ho·∫∑c image (bytes) cho Gemini ƒë·ªÉ tr√≠ch xu·∫•t JSON."""
    
    # S·ª≠ d·ª•ng model h·ªó tr·ª£ JSON mode (v√≠ d·ª•: gemini-2.5-flash)
    model = genai.GenerativeModel("gemini-2.5-flash")
    prompt = get_gemini_prompt()
    
    content_to_send = None
    if isinstance(text_or_image_data, str):
        content_to_send = text_or_image_data
    else:
        try:
            image_pil = Image.open(BytesIO(text_or_image_data))
            content_to_send = image_pil
        except Exception as e:
            print(f"[ERROR] Kh√¥ng th·ªÉ chuy·ªÉn bytes th√†nh ·∫£nh: {e}")
            return "{}"

    # Y√™u c·∫ßu Gemini tr·∫£ v·ªÅ JSON
    generation_config = genai.types.GenerationConfig(
        response_mime_type="application/json"
    )
    
    try:
        response = model.generate_content(
            [prompt, content_to_send],
            generation_config=generation_config
        )
        return response.text
    except Exception as e:
        st.error(f"L·ªói khi g·ªçi Gemini API: {e}")
        print(f"[ERROR] L·ªói g·ªçi Gemini API: {e}")
        return "{}"

# --- THAY ƒê·ªîI: H√ÄM TI·ªÄN X·ª¨ L√ù ·∫¢NH ƒê∆Ø·ª¢C T·ªêI ∆ØU H√ìA ---
# ================= Image Pre-processing Helpers =================
@st.cache_data(show_spinner=False)
def correct_skew(image_array_rgb):
    """
    Xoay ·∫£nh RGB (np.array) b·ªã nghi√™ng.
    Phi√™n b·∫£n n√†y ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a, d√πng contours thay v√¨ np.where, t·ªëc ƒë·ªô nhanh h∆°n.
    """
    try:
        # Chuy·ªÉn sang ·∫£nh x√°m
        image_gray = cv2.cvtColor(image_array_rgb, cv2.COLOR_RGB2GRAY)
        
        # Nh·ªã ph√¢n h√≥a ·∫£nh v√† ƒë·∫£o ng∆∞·ª£c (ch·ªØ tr·∫Øng, n·ªÅn ƒëen)
        _, thresh = cv2.threshold(image_gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)
        
        # --- T·ªêI ∆ØU H√ìA: D√πng findContours ---
        # T√¨m t·∫•t c·∫£ c√°c ƒë∆∞·ªùng vi·ªÅn (contours)
        contours, _ = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        
        # N·ªëi t·∫•t c·∫£ c√°c ƒëi·ªÉm t·ª´ c√°c contours l·∫°i th√†nh m·ªôt m·∫£ng
        if not contours:
            print("[INFO] Kh√¥ng t√¨m th·∫•y contours, b·ªè qua xoay.")
            return image_array_rgb
            
        all_points = np.concatenate([cnt for cnt in contours])
        
        # T√¨m h√¨nh ch·ªØ nh·∫≠t nh·ªè nh·∫•t bao quanh T·∫§T C·∫¢ c√°c ƒëi·ªÉm
        rect = cv2.minAreaRect(all_points)
        # --- K·∫æT TH√öC T·ªêI ∆ØU H√ìA ---
        
        angle = rect[-1]
        
        # Chu·∫©n h√≥a g√≥c:
        if angle < -45:
            angle = -(90 + angle)
        else:
            angle = -angle
        
        # N·∫øu g√≥c qu√° nh·ªè (·∫£nh ƒë√£ th·∫≥ng), b·ªè qua
        if abs(angle) < 0.1:
            print("[INFO] ·∫¢nh ƒë√£ th·∫≥ng, kh√¥ng xoay.")
            return image_array_rgb

        # Xoay ·∫£nh
        (h, w) = image_array_rgb.shape[:2]
        center = (w // 2, h // 2)
        M = cv2.getRotationMatrix2D(center, angle, 1.0)
        
        rotated = cv2.warpAffine(image_array_rgb, M, (w, h),
                                 flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_CONSTANT,
                                 borderValue=(255, 255, 255)) # Fill vi·ªÅn tr·∫Øng
        
        print(f"[INFO] ƒê√£ xoay ·∫£nh m·ªôt g√≥c: {angle:.2f} ƒë·ªô")
        return rotated
    except Exception as e:
        print(f"[ERROR] L·ªói khi xoay ·∫£nh: {e}")
        return image_array_rgb # Tr·∫£ v·ªÅ ·∫£nh g·ªëc n·∫øu l·ªói

# --- H√ÄM improve_contrast ƒê√É B·ªä X√ìA ---

# ================= Streamlit UI =================
st.set_page_config(page_title="Tr√≠ch xu·∫•t H√≥a ƒë∆°n", layout="wide")
st.title("üßæ Tr√¨nh tr√≠ch xu·∫•t Th√¥ng tin H√≥a ƒë∆°n")
st.write("T·∫£i l√™n m·ªôt ho·∫∑c nhi·ªÅu h√¨nh ·∫£nh h√≥a ƒë∆°n")

col1, col2 = st.columns([2, 3]) 

OCR_METHODS = ["Vision", "Google Vision", "PaddleOCR"] 
selected_ocr = st.sidebar.selectbox("Ch·ªçn ph∆∞∆°ng th·ª©c OCR/Vision", OCR_METHODS)

# --- ƒê√É X√ìA: C√ÅC T√ôY CH·ªåN TI·ªÄN X·ª¨ L√ù TRONG SIDEBAR ---


with col1:
    uploaded_files = st.file_uploader(
        "Ch·ªçn ·∫£nh h√≥a ƒë∆°n...", 
        type=["jpg", "jpeg", "png"],
        accept_multiple_files=True
    )
    
    if uploaded_files:
        st.write(f"ƒê√£ ch·ªçn {len(uploaded_files)} t·ªáp.")

        with st.expander(f"Xem {len(uploaded_files)} ·∫£nh ƒë√£ t·∫£i l√™n (preview)"):
            
            num_cols = 5 # S·ªë c·ªôt ƒë·ªÉ hi·ªÉn th·ªã ·∫£nh
            
            for i, uploaded_file in enumerate(uploaded_files):
                if i % num_cols == 0:
                    cols = st.columns(num_cols)
                
                image = Image.open(uploaded_file)
                
                with cols[i % num_cols]:
                    st.image(
                        image, 
                        caption=f"Hƒê {i+1}",
                        use_container_width=True 
                    )

    if st.button("Tr√≠ch xu·∫•t th√¥ng tin", type="primary", disabled=not uploaded_files):
        with st.spinner("ƒêang x·ª≠ l√Ω..."):
            
            master_items_list = []
            master_raw_responses = []
            master_invoice_totals = [] 

            for i, uploaded_file in enumerate(uploaded_files):
                st.info(f"ƒêang x·ª≠ l√Ω H√≥a ƒë∆°n s·ªë {i+1} ({uploaded_file.name})...")
                
                try:
                    # --- THAY ƒê·ªîI: LU·ªíNG X·ª¨ L√ù ·∫¢NH T·ª∞ ƒê·ªòNG ---
                    image_pil = Image.open(uploaded_file)
                    
                    # Chuy·ªÉn sang np.array (RGB) ƒë·ªÉ x·ª≠ l√Ω OpenCV
                    img_np_rgb = np.array(image_pil.convert("RGB"))

                    # B∆Ø·ªöC 1: TI·ªÄN X·ª¨ L√ù (T·ª∞ ƒê·ªòNG V√Ä NHANH)
                    # Ch·ªâ t·ª± ƒë·ªông xoay ·∫£nh, v√¨ h√†m n√†y ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a
                    with st.spinner(f"File {uploaded_file.name}: ƒêang t·ª± ƒë·ªông l√†m th·∫≥ng ·∫£nh..."):
                        img_np_rgb = correct_skew(img_np_rgb)
                    
                    # (ƒê√£ x√≥a b∆∞·ªõc tƒÉng t∆∞∆°ng ph·∫£n)
                    
                    # B∆Ø·ªöC 2: CHU·∫®N B·ªä D·ªÆ LI·ªÜU SAU KHI TI·ªÄN X·ª¨ L√ù
                    
                    # Chuy·ªÉn ·∫£nh ƒê√É X·ª¨ L√ù v·ªÅ l·∫°i PIL
                    image_pil_processed = Image.fromarray(img_np_rgb)

                    # Chu·∫©n b·ªã image bytes cho Vision v√† Google OCR (t·ª´ ·∫£nh ƒë√£ x·ª≠ l√Ω)
                    buffered = BytesIO()
                    save_format = "PNG" # PNG t·ªët h∆°n cho OCR sau khi x·ª≠ l√Ω
                    image_pil_processed.save(buffered, format=save_format)
                    image_bytes_for_ocr = buffered.getvalue()

                    # Chu·∫©n b·ªã ·∫£nh BGR cho PaddleOCR (t·ª´ ·∫£nh ƒë√£ x·ª≠ l√Ω)
                    # Chuy·ªÉn RGB (img_np_rgb) -> BGR (PaddleOCR d√πng BGR)
                    img_np_bgr_for_paddle = img_np_rgb[..., ::-1] 
                    # --- K·∫æT TH√öC THAY ƒê·ªîI LU·ªíNG X·ª¨ L√ù ·∫¢NH ---

                    ocr_text = None # L∆∞u k·∫øt qu·∫£ OCR trung gian
                    raw_response = None
                    
                    if selected_ocr == "Vision":
                        # G·ª≠i ·∫£nh ƒë√£ x·ª≠ l√Ω
                        raw_response = extract_invoice_json(image_bytes_for_ocr)
                    else:
                        if selected_ocr == "Google Vision":
                            # G·ª≠i ·∫£nh ƒë√£ x·ª≠ l√Ω
                            ocr_text = ocr_google_vision_api_key(image_bytes_for_ocr)
                        elif selected_ocr == "PaddleOCR":
                            # G·ª≠i ·∫£nh BGR ƒë√£ x·ª≠ l√Ω cho Paddle
                            ocr_text = ocr_paddle(img_np_bgr_for_paddle)
                        
                        if not ocr_text:
                            st.warning(f"File {uploaded_file.name}: OCR kh√¥ng tr·∫£ v·ªÅ k·∫øt qu·∫£.")
                            raw_response = "{}" 
                        else:
                            raw_response = extract_invoice_json(ocr_text)

                    # L∆∞u c·∫£ k·∫øt qu·∫£ OCR v√† JSON th√¥
                    master_raw_responses.append({
                        "hoa_don_so": i + 1,
                        "file": uploaded_file.name,
                        "ocr_text": ocr_text, # S·∫Ω l√† None n·∫øu d√πng 'Vision'
                        "response": raw_response
                    })

                    try:
                        # L√†m s·∫°ch JSON (lo·∫°i b·ªè markdown ` ```json `)
                        clean = raw_response.strip()
                        
                        json_start = clean.find('{')
                        json_end = clean.rfind('}')
                        
                        if json_start != -1 and json_end != -1 and json_end > json_start:
                            clean = clean[json_start:json_end+1]
                        else:
                            raise json.JSONDecodeError("Kh√¥ng t√¨m th·∫•y ƒë·ªëi t∆∞·ª£ng JSON h·ª£p l·ªá.", clean, 0)
                        
                        json_data = json.loads(clean)
                        
                        # --- KI·ªÇM TRA SCHEMA ---
                        if "items" not in json_data or not isinstance(json_data.get("items"), list):
                            st.warning(f"File {uploaded_file.name}: JSON tr·∫£ v·ªÅ kh√¥ng c√≥ 'items' ho·∫∑c 'items' kh√¥ng ph·∫£i l√† list. B·ªè qua items.")
                            json_data["items"] = [] # ƒê·∫∑t m·∫∑c ƒë·ªãnh ƒë·ªÉ code kh√¥ng l·ªói
                        
                        if "tong_tien" not in json_data:
                            json_data["tong_tien"] = None # ƒê·∫∑t m·∫∑c ƒë·ªãnh
                        # --- H·∫æT KI·ªÇM TRA SCHEMA ---
                        
                        if json_data:
                            items = json_data.get("items", [])
                            master_items_list.extend(items)
                            
                            tong_tien = json_data.get("tong_tien", None)
                            current_total_numeric = None
                            if tong_tien is not None:
                                try:
                                    # Chu·∫©n h√≥a s·ªë (lo·∫°i b·ªè d·∫•u '.', thay ',' b·∫±ng '.')
                                    if isinstance(tong_tien, str):
                                        tong_tien = tong_tien.replace(".", "").replace(",", ".")
                                    
                                    current_total_numeric = float(tong_tien)
                                except (ValueError, TypeError):
                                    pass # Gi·ªØ l√† None n·∫øu kh√¥ng th·ªÉ convert
                            
                            master_invoice_totals.append({
                                "id": i + 1,
                                "total_value": current_total_numeric,
                                "file_name": uploaded_file.name
                            })

                    except Exception as e:
                        st.error(f"L·ªói parse JSON cho t·ªáp {uploaded_file.name}: {e}")
                        print(f"[ERROR] JSON parse error: {e}\nRaw response:\n{raw_response}")

                except Exception as e:
                    st.error(f"L·ªói x·ª≠ l√Ω t·ªáp {uploaded_file.name}: {e}")
                    print(f"[ERROR] Main processing error: {e}")
                
                gc.collect() # D·ªçn d·∫πp r√°c
            
            # L∆∞u k·∫øt qu·∫£ v√†o session state ƒë·ªÉ hi·ªÉn th·ªã ·ªü col2
            st.session_state.aggregated_items = master_items_list
            st.session_state.invoice_totals = master_invoice_totals
            st.session_state.aggregated_raw = master_raw_responses
            
            st.success(f"ƒê√£ x·ª≠ l√Ω xong {len(uploaded_files)} t·ªáp!")
            
            # T·ª± ƒë·ªông refresh l·∫°i to√†n b·ªô trang ƒë·ªÉ hi·ªÉn th·ªã k·∫øt qu·∫£ ·ªü col2
            st.rerun()


# ================= Hi·ªÉn th·ªã k·∫øt qu·∫£ ·ªü C·ªôt 2 =================
with col2:
    if "invoice_totals" in st.session_state:
        st.subheader("T·ªïng ti·ªÅn theo T·ª´ng H√≥a ƒë∆°n")
        
        all_totals = st.session_state.invoice_totals
        grand_total = 0
        
        num_invoices = len(all_totals)
        
        if num_invoices > 0:
            
            for data in all_totals:
                total_val = data['total_value']
                
                value_str = "Kh√¥ng c√≥"
                if total_val is not None:
                    # ƒê·ªãnh d·∫°ng ti·ªÅn t·ªá Vi·ªát Nam
                    val_str_formatted = f"{total_val:,.0f}".replace(",", ".")
                    value_str = f"{val_str_formatted} VNƒê"
                
                st.metric(
                    label=f"H√≥a ƒë∆°n s·ªë {data['id']} ({data['file_name']})", 
                    value=value_str
                )
                
                if total_val is not None:
                    grand_total += total_val
        
        st.divider()
        val_str_formatted = f"{grand_total:,.0f}".replace(",", ".")
        st.metric("üéâ T·ªîNG C·ªòNG (T·∫•t c·∫£ h√≥a ƒë∆°n)", f"{val_str_formatted} VNƒê")
        st.divider()


    if "aggregated_items" in st.session_state:
        st.subheader("Chi ti·∫øt M·∫∑t h√†ng (T·ªïng h·ª£p)")
        items = st.session_state.aggregated_items
        
        if items: 
            df = pd.DataFrame(items)

            # ƒê·∫£m b·∫£o c√°c c·ªôt lu√¥n t·ªìn t·∫°i
            cols_to_add = ["ten_hang", "don_vi_tinh", "so_luong", "don_gia", "thanh_tien"]
            final_cols = [] 
            
            for c in cols_to_add:
                if c not in df.columns:
                    df[c] = None
                final_cols.append(c)
            
            df = df[final_cols] 
            df.columns = ["T√™n H√†ng", "ƒêV T√≠nh", "S·ªë L∆∞·ª£ng", "ƒê∆°n Gi√°", "Th√†nh Ti·ªÅn"]
            
            # --- D√ôNG st.data_editor ---
            st.write("B·∫°n c√≥ th·ªÉ nh·∫•p ƒë√∫p ƒë·ªÉ s·ª≠a l·ªói tr√≠ch xu·∫•t:")
            df_edited = st.data_editor(
                df, 
                use_container_width=True,
                num_rows="dynamic", # Cho ph√©p ng∆∞·ªùi d√πng th√™m/x√≥a h√†ng
                key="data_editor_results"
            )
            
            # L∆∞u l·∫°i df ƒë√£ ch·ªânh s·ª≠a ƒë·ªÉ export
            st.session_state.edited_items_df = df_edited
            
            # --- N√öT DOWNLOAD ---
            @st.cache_data
            def convert_df_to_csv(df_to_convert):
                # Chuy·ªÉn DataFrame th√†nh CSV, m√£ h√≥a utf-8
                return df_to_convert.to_csv(index=False).encode('utf-8-sig')

            csv_data = convert_df_to_csv(df_edited)
            
            st.download_button(
                label="üì• T·∫£i v·ªÅ CSV (d·ªØ li·ªáu ƒë√£ s·ª≠a)",
                data=csv_data,
                file_name="hoa_don_trich_xuat.csv",
                mime="text/csv",
            )

        else:
            st.warning("Kh√¥ng c√≥ m·∫∑t h√†ng n√†o ƒë∆∞·ª£c t√¨m th·∫•y.")

    if "aggregated_raw" in st.session_state:
        # --- EXPANDER CHI TI·∫æT H∆†N ---
        with st.expander("Xem d·ªØ li·ªáu th√¥ (OCR text v√† JSON response)"):
            for raw_data in st.session_state.aggregated_raw:
                st.subheader(f"File: {raw_data['file']} (Hƒê s·ªë {raw_data['hoa_don_so']})")
                
                # Hi·ªÉn th·ªã text OCR (n·∫øu c√≥)
                if raw_data['ocr_text']:
                    st.text("K·∫øt qu·∫£ OCR (ƒë√£ g·ª≠i cho Gemini):")
                    st.text_area(f"OCR_{raw_data['hoa_don_so']}", raw_data['ocr_text'], height=150, disabled=True)
                else:
                    st.info("Ch·∫°y ·ªü ch·∫ø ƒë·ªô 'Vision' (kh√¥ng c√≥ b∆∞·ªõc OCR text trung gian).")

                # Hi·ªÉn th·ªã JSON response
                st.text("K·∫øt qu·∫£ JSON (Gemini tr·∫£ v·ªÅ):")
                st.json(raw_data['response'])
                st.divider()
